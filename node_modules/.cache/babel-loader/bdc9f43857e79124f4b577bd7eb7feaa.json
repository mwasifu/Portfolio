{"ast":null,"code":"var _jsxFileName = \"/Users/wasif/Documents/Web Dev/portfolio/src/components/Speech.jsx\";\nimport React, { useEffect, useState, useRef } from \"react\"; // https://github.com/tensorflow/tfjs-models/tree/master/speech-commands\n// 0. Import depdendencies\n\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as speech from \"@tensorflow-models/speech-commands\"; // 4. Draw Ball\n\nimport { drawBall } from \"./utilities\";\n\nconst Speech = () => {\n  // 1. Create model and action states\n  const [model, setModel] = useState(null);\n  const [action, setAction] = useState(null);\n  const [labels, setLabels] = useState(null); // 6. Create Canvas Ref and x,y,r\n\n  const canvasRef = useRef(null);\n  const [x, setX] = useState(300);\n  const [y, setY] = useState(300);\n  const [r, setR] = useState(10); // 2. Create Recognizer\n\n  const loadModel = async () => {\n    const recognizer = await speech.create(\"BROWSER_FFT\");\n    console.log(\"Model loaded\");\n    await recognizer.ensureModelLoaded();\n    console.log(recognizer.wordLabels());\n    setModel(recognizer);\n    setLabels(recognizer.wordLabels());\n  };\n\n  useEffect(() => {\n    loadModel();\n  }, []);\n\n  function argMax(arr) {\n    return arr.map((x, i) => [x, i]).reduce((r, a) => a[0] > r[0] ? a : r)[1];\n  }\n\n  const pause = async () => {\n    model.stopListening();\n    console.log(\"Stopped recording from inside pause\");\n  };\n\n  const recognizeCommand = async () => {\n    model.listen(result => {\n      console.log(\"Started listening\");\n      console.log(result.scores);\n      setAction(labels[argMax(Object.values(result.scores))]);\n      console.log({\n        action\n      });\n    }, {\n      includeSpectrogram: true,\n      probabilityThreshold: 0.9\n    });\n  }; // // 7. Update ball state\n  // const numberMap = {\n  //   \"zero\":0,\n  //   \"one\":1,\n  //   \"two\":2,\n  //   \"three\":3,\n  //   \"four\":4,\n  //   \"five\":5,\n  //   \"six\":6,\n  //   \"seven\":7,\n  //   \"eight\":8,\n  //   \"nine\":9\n  // }\n  // useEffect(()=>{\n  //   // Update position x,y\n  //   const update = action === 'up' ? setY(y-10) : action===\"down\" ? setY(y+10) : action===\"left\" ? setX(x-10) : action===\"right\"? setX(x+10) : \"\"\n  //   // Update size r\n  //   if(Object.keys(numberMap).includes(action)){\n  //     setR(10*numberMap[action])\n  //   }\n  //   canvasRef.current.width = 600;\n  //   canvasRef.current.height = 600;\n  //   const ctx = canvasRef.current.getContext('2d')\n  //   console.log(x,y,r)\n  //   drawBall(ctx,x,y,r)\n  //   setAction('base')\n  // }, [action])\n  // // 3. Listen for Actions\n  // function argMax(arr){\n  //   return arr.map((x, i) => [x, i]).reduce((r, a) => (a[0] > r[0] ? a : r))[1];\n  // }\n  // const recognizeCommands = async () =>{\n  //   console.log('Listening for commands')\n  //   model.listen(result=>{\n  //     // console.log(labels[argMax(Object.values(result.scores))])\n  //     setAction(labels[argMax(Object.values(result.scores))])\n  //   }, {includeSpectrogram:true, probabilityThreshold:0.9})\n  //   // setTimeout(()=>model.stopListening(), 10e3)\n  // }\n\n\n  return /*#__PURE__*/React.createElement(\"div\", {\n    style: {\n      textAlign: \"center\",\n      margin: \"15%\"\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 107,\n      columnNumber: 5\n    }\n  }, /*#__PURE__*/React.createElement(\"div\", {\n    style: {\n      display: \"flex\",\n      columnGap: \"25%\"\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 122,\n      columnNumber: 1\n    }\n  }, /*#__PURE__*/React.createElement(\"button\", {\n    onClick: recognizeCommand,\n    style: {\n      borderRadius: \"200px\",\n      padding: \"3%\",\n      border: \"0\",\n      color: \"white\",\n      backgroundColor: \"gold\",\n      fontSize: \"2rem\",\n      margin: \"15 %\",\n      position: \"relative\"\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 123,\n      columnNumber: 1\n    }\n  }, \"Talk\"), /*#__PURE__*/React.createElement(\"button\", {\n    onClick: pause,\n    style: {\n      borderRadius: \"100px\",\n      padding: \"3%\",\n      border: \"0\",\n      color: \"white\",\n      backgroundColor: \"gold\",\n      fontSize: \"2rem\",\n      margin: \"15 %\",\n      position: \"relative\"\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 138,\n      columnNumber: 7\n    }\n  }, \"Stop\")), action ? /*#__PURE__*/React.createElement(\"div\", {\n    style: {\n      padding: \"5%\"\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 156,\n      columnNumber: 17\n    }\n  }, action) : /*#__PURE__*/React.createElement(\"div\", {\n    style: {\n      padding: \"5%\"\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 156,\n      columnNumber: 63\n    }\n  }, \"Nothing detected\"));\n};\n\nexport default Speech;","map":{"version":3,"sources":["/Users/wasif/Documents/Web Dev/portfolio/src/components/Speech.jsx"],"names":["React","useEffect","useState","useRef","tf","speech","drawBall","Speech","model","setModel","action","setAction","labels","setLabels","canvasRef","x","setX","y","setY","r","setR","loadModel","recognizer","create","console","log","ensureModelLoaded","wordLabels","argMax","arr","map","i","reduce","a","pause","stopListening","recognizeCommand","listen","result","scores","Object","values","includeSpectrogram","probabilityThreshold","textAlign","margin","display","columnGap","borderRadius","padding","border","color","backgroundColor","fontSize","position"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,EAA2BC,QAA3B,EAAqCC,MAArC,QAAmD,OAAnD,C,CACA;AAEA;;AACA,OAAO,KAAKC,EAAZ,MAAoB,kBAApB;AACA,OAAO,KAAKC,MAAZ,MAAwB,oCAAxB,C,CAEA;;AACA,SAASC,QAAT,QAAyB,aAAzB;;AAEA,MAAMC,MAAM,GAAG,MAAM;AACnB;AACA,QAAM,CAACC,KAAD,EAAQC,QAAR,IAAoBP,QAAQ,CAAC,IAAD,CAAlC;AACA,QAAM,CAACQ,MAAD,EAASC,SAAT,IAAsBT,QAAQ,CAAC,IAAD,CAApC;AACA,QAAM,CAACU,MAAD,EAASC,SAAT,IAAsBX,QAAQ,CAAC,IAAD,CAApC,CAJmB,CAMnB;;AACA,QAAMY,SAAS,GAAGX,MAAM,CAAC,IAAD,CAAxB;AACA,QAAM,CAACY,CAAD,EAAIC,IAAJ,IAAYd,QAAQ,CAAC,GAAD,CAA1B;AACA,QAAM,CAACe,CAAD,EAAIC,IAAJ,IAAYhB,QAAQ,CAAC,GAAD,CAA1B;AACA,QAAM,CAACiB,CAAD,EAAIC,IAAJ,IAAYlB,QAAQ,CAAC,EAAD,CAA1B,CAVmB,CAYnB;;AACA,QAAMmB,SAAS,GAAG,YAAY;AAC5B,UAAMC,UAAU,GAAG,MAAMjB,MAAM,CAACkB,MAAP,CAAc,aAAd,CAAzB;AACAC,IAAAA,OAAO,CAACC,GAAR,CAAY,cAAZ;AACA,UAAMH,UAAU,CAACI,iBAAX,EAAN;AACAF,IAAAA,OAAO,CAACC,GAAR,CAAYH,UAAU,CAACK,UAAX,EAAZ;AACAlB,IAAAA,QAAQ,CAACa,UAAD,CAAR;AACAT,IAAAA,SAAS,CAACS,UAAU,CAACK,UAAX,EAAD,CAAT;AACD,GAPD;;AASA1B,EAAAA,SAAS,CAAC,MAAM;AACdoB,IAAAA,SAAS;AACV,GAFQ,EAEN,EAFM,CAAT;;AAIA,WAASO,MAAT,CAAgBC,GAAhB,EAAqB;AACnB,WAAOA,GAAG,CAACC,GAAJ,CAAQ,CAACf,CAAD,EAAIgB,CAAJ,KAAU,CAAChB,CAAD,EAAIgB,CAAJ,CAAlB,EAA0BC,MAA1B,CAAiC,CAACb,CAAD,EAAIc,CAAJ,KAAWA,CAAC,CAAC,CAAD,CAAD,GAAOd,CAAC,CAAC,CAAD,CAAR,GAAcc,CAAd,GAAkBd,CAA9D,EAAkE,CAAlE,CAAP;AACD;;AAED,QAAMe,KAAK,GAAG,YAAY;AACxB1B,IAAAA,KAAK,CAAC2B,aAAN;AACAX,IAAAA,OAAO,CAACC,GAAR,CAAY,qCAAZ;AACD,GAHD;;AAKA,QAAMW,gBAAgB,GAAG,YAAY;AACnC5B,IAAAA,KAAK,CAAC6B,MAAN,CACGC,MAAD,IAAY;AACVd,MAAAA,OAAO,CAACC,GAAR,CAAY,mBAAZ;AACAD,MAAAA,OAAO,CAACC,GAAR,CAAYa,MAAM,CAACC,MAAnB;AACA5B,MAAAA,SAAS,CAACC,MAAM,CAACgB,MAAM,CAACY,MAAM,CAACC,MAAP,CAAcH,MAAM,CAACC,MAArB,CAAD,CAAP,CAAP,CAAT;AACAf,MAAAA,OAAO,CAACC,GAAR,CAAY;AAACf,QAAAA;AAAD,OAAZ;AACD,KANH,EAOE;AACEgC,MAAAA,kBAAkB,EAAE,IADtB;AAEEC,MAAAA,oBAAoB,EAAE;AAFxB,KAPF;AAYD,GAbD,CAnCmB,CAkDnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;;AAEA,sBACE;AAAK,IAAA,KAAK,EAAE;AAAEC,MAAAA,SAAS,EAAE,QAAb;AAAuBC,MAAAA,MAAM,EAAE;AAA/B,KAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAeJ;AAAK,IAAA,KAAK,EAAE;AAACC,MAAAA,OAAO,EAAE,MAAV;AAAkBC,MAAAA,SAAS,EAAE;AAA7B,KAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACA;AACQ,IAAA,OAAO,EAAEX,gBADjB;AAEQ,IAAA,KAAK,EAAE;AACLY,MAAAA,YAAY,EAAE,OADT;AAELC,MAAAA,OAAO,EAAE,IAFJ;AAGLC,MAAAA,MAAM,EAAE,GAHH;AAILC,MAAAA,KAAK,EAAE,OAJF;AAKLC,MAAAA,eAAe,EAAE,MALZ;AAMLC,MAAAA,QAAQ,EAAE,MANL;AAOLR,MAAAA,MAAM,EAAE,MAPH;AAQLS,MAAAA,QAAQ,EAAE;AARL,KAFf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YADA,eAgBM;AACE,IAAA,OAAO,EAAEpB,KADX;AAEE,IAAA,KAAK,EAAE;AACLc,MAAAA,YAAY,EAAE,OADT;AAELC,MAAAA,OAAO,EAAE,IAFJ;AAGLC,MAAAA,MAAM,EAAE,GAHH;AAILC,MAAAA,KAAK,EAAE,OAJF;AAKLC,MAAAA,eAAe,EAAE,MALZ;AAMLC,MAAAA,QAAQ,EAAE,MANL;AAOLR,MAAAA,MAAM,EAAE,MAPH;AAQLS,MAAAA,QAAQ,EAAE;AARL,KAFT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAhBN,CAfI,EAiDG5C,MAAM,gBAAG;AAAK,IAAA,KAAK,EAAE;AAACuC,MAAAA,OAAO,EAAE;AAAV,KAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAA8BvC,MAA9B,CAAH,gBAAiD;AAAK,IAAA,KAAK,EAAE;AAACuC,MAAAA,OAAO,EAAE;AAAV,KAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAjD1D,CADF;AAuDD,CAtJD;;AAwJA,eAAe1C,MAAf","sourcesContent":["import React, { useEffect, useState, useRef } from \"react\";\n// https://github.com/tensorflow/tfjs-models/tree/master/speech-commands\n\n// 0. Import depdendencies\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as speech from \"@tensorflow-models/speech-commands\";\n\n// 4. Draw Ball\nimport { drawBall } from \"./utilities\";\n\nconst Speech = () => {\n  // 1. Create model and action states\n  const [model, setModel] = useState(null);\n  const [action, setAction] = useState(null);\n  const [labels, setLabels] = useState(null);\n\n  // 6. Create Canvas Ref and x,y,r\n  const canvasRef = useRef(null);\n  const [x, setX] = useState(300);\n  const [y, setY] = useState(300);\n  const [r, setR] = useState(10);\n\n  // 2. Create Recognizer\n  const loadModel = async () => {\n    const recognizer = await speech.create(\"BROWSER_FFT\");\n    console.log(\"Model loaded\");\n    await recognizer.ensureModelLoaded();\n    console.log(recognizer.wordLabels());\n    setModel(recognizer);\n    setLabels(recognizer.wordLabels());\n  };\n\n  useEffect(() => {\n    loadModel();\n  }, []);\n\n  function argMax(arr) {\n    return arr.map((x, i) => [x, i]).reduce((r, a) => (a[0] > r[0] ? a : r))[1];\n  }\n\n  const pause = async () => {\n    model.stopListening();\n    console.log(\"Stopped recording from inside pause\");\n  };\n\n  const recognizeCommand = async () => {\n    model.listen(\n      (result) => {\n        console.log(\"Started listening\");\n        console.log(result.scores);\n        setAction(labels[argMax(Object.values(result.scores))]);\n        console.log({action});\n      },\n      {\n        includeSpectrogram: true,\n        probabilityThreshold: 0.9,\n      }\n    );\n  };\n\n  // // 7. Update ball state\n  // const numberMap = {\n  //   \"zero\":0,\n  //   \"one\":1,\n  //   \"two\":2,\n  //   \"three\":3,\n  //   \"four\":4,\n  //   \"five\":5,\n  //   \"six\":6,\n  //   \"seven\":7,\n  //   \"eight\":8,\n  //   \"nine\":9\n  // }\n\n  // useEffect(()=>{\n  //   // Update position x,y\n  //   const update = action === 'up' ? setY(y-10) : action===\"down\" ? setY(y+10) : action===\"left\" ? setX(x-10) : action===\"right\"? setX(x+10) : \"\"\n  //   // Update size r\n  //   if(Object.keys(numberMap).includes(action)){\n  //     setR(10*numberMap[action])\n  //   }\n\n  //   canvasRef.current.width = 600;\n  //   canvasRef.current.height = 600;\n  //   const ctx = canvasRef.current.getContext('2d')\n  //   console.log(x,y,r)\n  //   drawBall(ctx,x,y,r)\n  //   setAction('base')\n  // }, [action])\n\n  // // 3. Listen for Actions\n  // function argMax(arr){\n  //   return arr.map((x, i) => [x, i]).reduce((r, a) => (a[0] > r[0] ? a : r))[1];\n  // }\n\n  // const recognizeCommands = async () =>{\n  //   console.log('Listening for commands')\n  //   model.listen(result=>{\n  //     // console.log(labels[argMax(Object.values(result.scores))])\n  //     setAction(labels[argMax(Object.values(result.scores))])\n\n  //   }, {includeSpectrogram:true, probabilityThreshold:0.9})\n  //   // setTimeout(()=>model.stopListening(), 10e3)\n  // }\n\n  return (\n    <div style={{ textAlign: \"center\", margin: \"15%\"}}>\n      {/* 5. Setup Canvas */}\n      {/* <canvas \n        ref={canvasRef}\n        style={{\n          marginLeft: \"auto\",\n          marginRight: \"auto\",\n          left: 0,\n          right: 0,\n          textAlign: \"center\",\n          zindex: 9,\n          width: 640,\n          height: 640,\n        }}\n        /> */}\n<div style={{display: \"flex\", columnGap: \"25%\"}}>\n<button\n        onClick={recognizeCommand}\n        style={{\n          borderRadius: \"200px\",\n          padding: \"3%\",\n          border: \"0\",\n          color: \"white\",\n          backgroundColor: \"gold\",\n          fontSize: \"2rem\",\n          margin: \"15 %\",\n          position: \"relative\",\n        }}\n      >\n        Talk\n      </button>\n      <button\n        onClick={pause}\n        style={{\n          borderRadius: \"100px\",\n          padding: \"3%\",\n          border: \"0\",\n          color: \"white\",\n          backgroundColor: \"gold\",\n          fontSize: \"2rem\",\n          margin: \"15 %\",\n          position: \"relative\",\n        }}\n      >\n        Stop\n      </button>\n</div>\n\n\n      {action ? <div style={{padding: \"5%\"}}>{action}</div> : <div style={{padding: \"5%\"}}>Nothing detected</div>}\n\n      {/* {action ? <div>{action}</div>:<div>No Action Detected</div> } */}\n    </div>\n  );\n};\n\nexport default Speech;\n"]},"metadata":{},"sourceType":"module"}