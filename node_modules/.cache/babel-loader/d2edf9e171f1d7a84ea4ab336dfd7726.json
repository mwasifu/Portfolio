{"ast":null,"code":"var _jsxFileName = \"/Users/wasif/Documents/Web Dev/portfolio/src/components/Speech.jsx\";\nimport React, { useEffect, useState, useRef } from 'react'; // https://github.com/tensorflow/tfjs-models/tree/master/speech-commands\n// 0. Import depdendencies\n\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as speech from \"@tensorflow-models/speech-commands\"; // 4. Draw Ball\n\nimport { drawBall } from \"./utilities\";\n\nconst Speech = () => {\n  // 1. Create model and action states\n  const [model, setModel] = useState(null);\n  const [action, setAction] = useState(null);\n  const [labels, setLabels] = useState(null); // 6. Create Canvas Ref and x,y,r\n\n  const canvasRef = useRef(null);\n  const [x, setX] = useState(300);\n  const [y, setY] = useState(300);\n  const [r, setR] = useState(10); // 2. Create Recognizer\n\n  const loadModel = async () => {\n    const recognizer = await speech.create(\"BROWSER_FFT\");\n    console.log(\"Model loaded\");\n    await recognizer.ensureModelLoaded();\n    console.log(recognizer.wordLabels());\n    setModel(recognizer);\n    setLabels(recognizer.wordLabels());\n  };\n\n  useEffect(() => {\n    loadModel();\n  }, []);\n\n  function argMax(arr) {\n    return arr.map((x, i) => [x, i]).reduce((r, a) => a[0] > r[0] ? a : r)[1];\n  }\n\n  const pause = async () => {\n    model.stopListening();\n    console.log(\"Stopped recording from inside pause\");\n  };\n\n  const recognizeCommand = async () => {\n    model.listen(result => {\n      console.log(\"Started listening\");\n      console.log(result.scores);\n      setAction(labels[argMax(Object.values(result.scores))]);\n      console.log(action);\n    }, {\n      includeSpectrogram: true,\n      probabilityThreshold: 0.9\n    });\n  }; // // 7. Update ball state\n  // const numberMap = {\n  //   \"zero\":0,\n  //   \"one\":1,\n  //   \"two\":2,\n  //   \"three\":3,\n  //   \"four\":4,\n  //   \"five\":5,\n  //   \"six\":6,\n  //   \"seven\":7,\n  //   \"eight\":8,\n  //   \"nine\":9\n  // }\n  // useEffect(()=>{\n  //   // Update position x,y\n  //   const update = action === 'up' ? setY(y-10) : action===\"down\" ? setY(y+10) : action===\"left\" ? setX(x-10) : action===\"right\"? setX(x+10) : \"\"\n  //   // Update size r\n  //   if(Object.keys(numberMap).includes(action)){\n  //     setR(10*numberMap[action])\n  //   }\n  //   canvasRef.current.width = 600;\n  //   canvasRef.current.height = 600;\n  //   const ctx = canvasRef.current.getContext('2d')\n  //   console.log(x,y,r)\n  //   drawBall(ctx,x,y,r)\n  //   setAction('base')\n  // }, [action])\n  // // 3. Listen for Actions\n  // function argMax(arr){\n  //   return arr.map((x, i) => [x, i]).reduce((r, a) => (a[0] > r[0] ? a : r))[1];\n  // }\n  // const recognizeCommands = async () =>{\n  //   console.log('Listening for commands')\n  //   model.listen(result=>{\n  //     // console.log(labels[argMax(Object.values(result.scores))])\n  //     setAction(labels[argMax(Object.values(result.scores))])\n  //   }, {includeSpectrogram:true, probabilityThreshold:0.9})\n  //   // setTimeout(()=>model.stopListening(), 10e3)\n  // }\n\n\n  return /*#__PURE__*/React.createElement(\"div\", {\n    style: {\n      textAlign: 'center',\n      alignContent: \"space-around\"\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 110,\n      columnNumber: 5\n    }\n  }, /*#__PURE__*/React.createElement(\"button\", {\n    onClick: recognizeCommand,\n    style: {\n      borderRadius: \"100px\",\n      padding: \"3%\",\n      border: \"0\",\n      color: \"white\",\n      backgroundColor: \"gold\",\n      fontSize: \"2rem\",\n      margin: \"15 %\",\n      position: \"relative\"\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 126,\n      columnNumber: 11\n    }\n  }, \"Talk\"), /*#__PURE__*/React.createElement(\"button\", {\n    onClick: pause,\n    style: {\n      borderRadius: \"100px\",\n      padding: \"3%\",\n      border: \"0\",\n      color: \"white\",\n      backgroundColor: \"gold\",\n      fontSize: \"2rem\",\n      margin: \"15 %\",\n      position: \"relative\"\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 127,\n      columnNumber: 11\n    }\n  }, \"Stop\"));\n};\n\nexport default Speech;","map":{"version":3,"sources":["/Users/wasif/Documents/Web Dev/portfolio/src/components/Speech.jsx"],"names":["React","useEffect","useState","useRef","tf","speech","drawBall","Speech","model","setModel","action","setAction","labels","setLabels","canvasRef","x","setX","y","setY","r","setR","loadModel","recognizer","create","console","log","ensureModelLoaded","wordLabels","argMax","arr","map","i","reduce","a","pause","stopListening","recognizeCommand","listen","result","scores","Object","values","includeSpectrogram","probabilityThreshold","textAlign","alignContent","borderRadius","padding","border","color","backgroundColor","fontSize","margin","position"],"mappings":";AAAA,OAAOA,KAAP,IAAeC,SAAf,EAA0BC,QAA1B,EAAoCC,MAApC,QAAiD,OAAjD,C,CACA;AAEA;;AACA,OAAO,KAAKC,EAAZ,MAAoB,kBAApB;AACA,OAAO,KAAKC,MAAZ,MAAwB,oCAAxB,C,CAGA;;AACA,SAAQC,QAAR,QAAuB,aAAvB;;AAEA,MAAMC,MAAM,GAAG,MAAM;AACrB;AACA,QAAM,CAACC,KAAD,EAAQC,QAAR,IAAoBP,QAAQ,CAAC,IAAD,CAAlC;AACA,QAAM,CAACQ,MAAD,EAASC,SAAT,IAAsBT,QAAQ,CAAC,IAAD,CAApC;AACA,QAAM,CAACU,MAAD,EAASC,SAAT,IAAsBX,QAAQ,CAAC,IAAD,CAApC,CAJqB,CAMrB;;AACA,QAAMY,SAAS,GAAGX,MAAM,CAAC,IAAD,CAAxB;AACA,QAAM,CAACY,CAAD,EAAIC,IAAJ,IAAYd,QAAQ,CAAC,GAAD,CAA1B;AACA,QAAM,CAACe,CAAD,EAAIC,IAAJ,IAAYhB,QAAQ,CAAC,GAAD,CAA1B;AACA,QAAM,CAACiB,CAAD,EAAIC,IAAJ,IAAYlB,QAAQ,CAAC,EAAD,CAA1B,CAVqB,CAYrB;;AACA,QAAMmB,SAAS,GAAG,YAAY;AAC1B,UAAMC,UAAU,GAAG,MAAMjB,MAAM,CAACkB,MAAP,CAAc,aAAd,CAAzB;AACAC,IAAAA,OAAO,CAACC,GAAR,CAAY,cAAZ;AACA,UAAMH,UAAU,CAACI,iBAAX,EAAN;AACAF,IAAAA,OAAO,CAACC,GAAR,CAAYH,UAAU,CAACK,UAAX,EAAZ;AACAlB,IAAAA,QAAQ,CAACa,UAAD,CAAR;AACAT,IAAAA,SAAS,CAACS,UAAU,CAACK,UAAX,EAAD,CAAT;AACH,GAPD;;AASA1B,EAAAA,SAAS,CAAC,MAAM;AAACoB,IAAAA,SAAS;AAAG,GAApB,EAAsB,EAAtB,CAAT;;AAEA,WAASO,MAAT,CAAgBC,GAAhB,EAAoB;AAChB,WAAOA,GAAG,CAACC,GAAJ,CAAQ,CAACf,CAAD,EAAGgB,CAAH,KAAS,CAAChB,CAAD,EAAGgB,CAAH,CAAjB,EAAwBC,MAAxB,CAA+B,CAACb,CAAD,EAAGc,CAAH,KAAUA,CAAC,CAAC,CAAD,CAAD,GAAOd,CAAC,CAAC,CAAD,CAAR,GAAcc,CAAd,GAAkBd,CAA3D,EAAgE,CAAhE,CAAP;AACH;;AAED,QAAMe,KAAK,GAAG,YAAY;AAGlB1B,IAAAA,KAAK,CAAC2B,aAAN;AACAX,IAAAA,OAAO,CAACC,GAAR,CAAY,qCAAZ;AAGP,GAPD;;AASA,QAAMW,gBAAgB,GAAG,YAAY;AACjC5B,IAAAA,KAAK,CAAC6B,MAAN,CAAaC,MAAM,IAAI;AACnBd,MAAAA,OAAO,CAACC,GAAR,CAAY,mBAAZ;AACGD,MAAAA,OAAO,CAACC,GAAR,CAAYa,MAAM,CAACC,MAAnB;AACC5B,MAAAA,SAAS,CAACC,MAAM,CAACgB,MAAM,CAACY,MAAM,CAACC,MAAP,CAAcH,MAAM,CAACC,MAArB,CAAD,CAAP,CAAP,CAAT;AACAf,MAAAA,OAAO,CAACC,GAAR,CAAYf,MAAZ;AAEP,KAND,EAMG;AACCgC,MAAAA,kBAAkB,EAAE,IADrB;AAECC,MAAAA,oBAAoB,EAAE;AAFvB,KANH;AAUH,GAXD,CArCqB,CAoDrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;;AAEE,sBACE;AAAK,IAAA,KAAK,EAAE;AAACC,MAAAA,SAAS,EAAE,QAAZ;AAAsBC,MAAAA,YAAY,EAAE;AAApC,KAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAgBM;AAAQ,IAAA,OAAO,EAAET,gBAAjB;AAAmC,IAAA,KAAK,EAAE;AAACU,MAAAA,YAAY,EAAE,OAAf;AAAwBC,MAAAA,OAAO,EAAE,IAAjC;AAAuCC,MAAAA,MAAM,EAAE,GAA/C;AAAoDC,MAAAA,KAAK,EAAE,OAA3D;AAAoEC,MAAAA,eAAe,EAAE,MAArF;AAA6FC,MAAAA,QAAQ,EAAE,MAAvG;AAA+GC,MAAAA,MAAM,EAAE,MAAvH;AAA+HC,MAAAA,QAAQ,EAAE;AAAzI,KAA1C;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAhBN,eAiBM;AAAQ,IAAA,OAAO,EAAEnB,KAAjB;AAAwB,IAAA,KAAK,EAAE;AAACY,MAAAA,YAAY,EAAE,OAAf;AAAwBC,MAAAA,OAAO,EAAE,IAAjC;AAAuCC,MAAAA,MAAM,EAAE,GAA/C;AAAoDC,MAAAA,KAAK,EAAE,OAA3D;AAAoEC,MAAAA,eAAe,EAAE,MAArF;AAA6FC,MAAAA,QAAQ,EAAE,MAAvG;AAA+GC,MAAAA,MAAM,EAAE,MAAvH;AAA+HC,MAAAA,QAAQ,EAAE;AAAzI,KAA/B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAjBN,CADF;AAuBD,CAxHD;;AA0HA,eAAe9C,MAAf","sourcesContent":["import React, {useEffect, useState, useRef} from 'react';\n// https://github.com/tensorflow/tfjs-models/tree/master/speech-commands\n\n// 0. Import depdendencies\nimport * as tf from \"@tensorflow/tfjs\"\nimport * as speech from \"@tensorflow-models/speech-commands\"\n\n \n// 4. Draw Ball\nimport {drawBall} from \"./utilities\";\n\nconst Speech = () => {\n// 1. Create model and action states\nconst [model, setModel] = useState(null)\nconst [action, setAction] = useState(null)\nconst [labels, setLabels] = useState(null)\n\n// 6. Create Canvas Ref and x,y,r\nconst canvasRef = useRef(null); \nconst [x, setX] = useState(300)\nconst [y, setY] = useState(300)\nconst [r, setR] = useState(10)\n\n// 2. Create Recognizer\nconst loadModel = async () => {\n    const recognizer = await speech.create(\"BROWSER_FFT\");\n    console.log(\"Model loaded\");\n    await recognizer.ensureModelLoaded();\n    console.log(recognizer.wordLabels());\n    setModel(recognizer);\n    setLabels(recognizer.wordLabels()); \n}\n\nuseEffect(() => {loadModel()}, []);\n\nfunction argMax(arr){\n    return arr.map((x,i) => [x,i]).reduce((r,a) => (a[0] > r[0] ? a : r ))[1];\n}\n\nconst pause = async () => {\n\n\n        model.stopListening();\n        console.log(\"Stopped recording from inside pause\");\n\n\n}\n\nconst recognizeCommand = async () => {\n    model.listen(result => {\n        console.log(\"Started listening\");\n           console.log(result.scores);\n            setAction(labels[argMax(Object.values(result.scores))])\n            console.log(action);\n            \n    }, {\n        includeSpectrogram: true,\n        probabilityThreshold: 0.9\n    });\n}\n\n\n\n// // 7. Update ball state\n// const numberMap = {\n//   \"zero\":0,\n//   \"one\":1,\n//   \"two\":2,\n//   \"three\":3,\n//   \"four\":4,\n//   \"five\":5,\n//   \"six\":6,\n//   \"seven\":7,\n//   \"eight\":8,\n//   \"nine\":9\n// }\n\n// useEffect(()=>{\n//   // Update position x,y\n//   const update = action === 'up' ? setY(y-10) : action===\"down\" ? setY(y+10) : action===\"left\" ? setX(x-10) : action===\"right\"? setX(x+10) : \"\"\n//   // Update size r\n//   if(Object.keys(numberMap).includes(action)){\n//     setR(10*numberMap[action])\n//   }\n\n//   canvasRef.current.width = 600;\n//   canvasRef.current.height = 600;\n//   const ctx = canvasRef.current.getContext('2d')\n//   console.log(x,y,r)\n//   drawBall(ctx,x,y,r)\n//   setAction('base')\n// }, [action])\n\n// // 3. Listen for Actions\n// function argMax(arr){\n//   return arr.map((x, i) => [x, i]).reduce((r, a) => (a[0] > r[0] ? a : r))[1];\n// }\n\n// const recognizeCommands = async () =>{\n//   console.log('Listening for commands')\n//   model.listen(result=>{\n//     // console.log(labels[argMax(Object.values(result.scores))])\n//     setAction(labels[argMax(Object.values(result.scores))])\n    \n//   }, {includeSpectrogram:true, probabilityThreshold:0.9})\n//   // setTimeout(()=>model.stopListening(), 10e3)\n// }\n\n  return (\n    <div style={{textAlign: 'center', alignContent: \"space-around\"}}>\n        {/* 5. Setup Canvas */}\n        {/* <canvas \n        ref={canvasRef}\n        style={{\n          marginLeft: \"auto\",\n          marginRight: \"auto\",\n          left: 0,\n          right: 0,\n          textAlign: \"center\",\n          zindex: 9,\n          width: 640,\n          height: 640,\n        }}\n        /> */}\n\n          <button onClick={recognizeCommand} style={{borderRadius: \"100px\", padding: \"3%\", border: \"0\", color: \"white\", backgroundColor: \"gold\", fontSize: \"2rem\", margin: \"15 %\", position: \"relative\"}}>Talk</button>\n          <button onClick={pause} style={{borderRadius: \"100px\", padding: \"3%\", border: \"0\", color: \"white\", backgroundColor: \"gold\", fontSize: \"2rem\", margin: \"15 %\", position: \"relative\"}}>Stop</button>\n          \n          {/* {action ? <div>{action}</div>:<div>No Action Detected</div> } */}\n    </div>\n  );\n}\n\nexport default Speech;"]},"metadata":{},"sourceType":"module"}